#!/bin/bash
#NB "strict" mode is used if run as a script

FS_BASE=${FS_BASE:-'/usr2'}
FS_PATH=${FS_PATH:-"${FS_BASE}/fs"}
LOG_PATH=${LOG_PATH:-"${FS_BASE}/log"}
PROC_PATH=${PROC_PATH:-"${FS_BASE}/proc"}
SCHED_PATH=${SCHED_PATH:-"${FS_BASE}/sched"}

# Lines to remove from log file to make "reduced" logs
# Use egrep syntax
REDUCE_PATTERN='^[:.0-9]*#rdtc'

# Added to filename before extension of log files with all data
FULL_SUFFIX='_full'
# Check for compressed logs
COMPRESSED_EXT='gz'

usage_long() {
    cat <<EOF
Push log files to the data centers.

USAGE: 
    ${black}$0 [options] ARG [ARG...]${normal}

ARG can be an experiment ID or the path of a file.

${underline}Options:${normal}
    ${black}-l${normal}            Use latest log in $LOG_PATH (other than 'station.log'
                  or 'point.log')
    ${black}-t${normal}            Test run. Print commands, do not actually push files to server
    ${black}-h${normal}            Print this message
    ${black}-c CENTER${normal}     Push files to data CENTER. Overrides the DATA_CENTERS
                  environment variable. Flag can be given multiple times.
    ${black}-p${normal}            Also push proc file
    ${black}-q${normal}            Quiet mode.
    ${black}-z${normal}            Push compressed log (full if contains multicast data)

If the log containing RDBE multicast data:

1.  If not already done so, the log file will be renamed to
    '$LOG_PATH/<log>_full.log'

2.  Unless '-z' is supplied, a reduced log file, without multicast data, is
    created in /tmp and this is transferred to the data center.

To see progress when compressing and reducing, install the 'pv' package.

plog requires the STATION environment variable be set to the lower case
two-letter station code in. E.g. add the following ~/.login (tcsh) or
~/.profile (bash):

    setenv STATION gs ${blue}#tcsh${normal}
    export STATION=gs ${blue}#bash${normal}

Data centers are specified in the DATA_CENTERS environment variable which can
contain CDDIS, OPAR, BKG, HAYSTACK (VGOS only). Multiple centers are separated
with a space. E.g. add the following to your login script

    setenv DATA_CENTERS "CDDIS HAYSTACK" ${blue}#tcsh${normal}
    export DATA_CENTERS="CDDIS HAYSTACK" ${blue}#bash${normal}

If DATA_CENTERS is empty, plog defaults to CDDIS.

Data center login must be configured in "~/.netrc".  For example, for CDDIS

    machine urs.earthdata.nasa.gov
        login mycddisuser
        password secret

See NETRC(5) for more details.

Examples of usage:
    ${blue}# push log for latest session, sending reduced if needed${normal}
    plog -l
    ${blue}# push log and proc files for session vgp007${normal}
    plog -p vgp007
    ${blue}# push (full) compressed log for vgp007${normal}
    plot -z vgp007
    ${blue}# push everything in /usr2/log to Haystack${normal}
    plog -c HAYSTACK /usr2/log/*.log

EOF
}

# Check if stdout is a terminal
if test -t 1; then
    # see if it supports colors...
    ncolors=$(tput colors)
    if test -n "$ncolors" && test $ncolors -ge 8; then
        bold="$(tput bold)"
        underline="$(tput smul)"
        standout="$(tput smso)"
        normal="$(tput sgr0)"
        black="$(tput setaf 0)"
        red="$(tput setaf 1)"
        green="$(tput setaf 2)"
        yellow="$(tput setaf 3)"
        blue="$(tput setaf 4)"
        magenta="$(tput setaf 5)"
        cyan="$(tput setaf 6)"
        white="$(tput setaf 7)"
    fi
else
        bold=
        underline=
        standout=
        normal=
        black=
        red=
        green=
        yellow=
        blue=
        magenta=
        cyan=
        white=
fi


usage(){
    cat <<EOF
Usage: $0 [-l] [-t] [-h] [-c CENTER] ARG ...
Push log file(s) to the data centers.
EOF
}

fatal(){
    echo -e "${red}ERROR:${normal} plog:" "$*" >&2
    exit 1
}

warn(){
    if [[ -z "$QUIET" ]]; then
        echo -e "${yellow}WARN:${normal} plog:" "$@" >&2
    fi
}
info(){
    if [[ -z "$QUIET" ]]; then
        echo -e "${green}INFO:${normal} plog:" "$@" >&2
    fi
}

# Check if pv (Pipe Viewer) is installed.
# Used for progress meters
PV=$(which pv)
if [[ $? -ne 0 ]]; then
    PV="cat"
fi

## Put Commands
# Helper functions for data center commands
# follow signatures
# f URL file [file...]
pftp() {
    if ! which curl > /dev/null; then
        fatal "'curl' not found"
    fi
    URL="$1"; shift
    local F=($@) #Turn into an array so IFS is used in expansion
    local IFS=","
    $DRY curl -n -T "{${F[*]}}" "ftp://$URL/"
}

pscp() {
    URL="$1"; shift
    $DRY scp $@ "$URL"
}
dummy() {
    echo $@
}

## Utility functions
# Format an array with first arg as template. Used for curl.
fmtarray() {
    local FMT="$1"; shift
    for f in $@; do
        printf "$FMT" "$f"
    done
}
# Add file to upload queue
add() {
    FILES+=($@)
    info queued $@
}

CDDIS_URL="https://depot.cddis.eosdis.nasa.gov/CDDIS_FileUpload"
cddis() {
    # Check if curl is installed.
    if ! which curl > /dev/null; then
        fatal "'curl' not found"
    fi

    if [[ ! -e "$HOME/.netrc" ]]; then
        fatal "$HOME/.netrc not found, see usage"
    fi

    if ! grep -q urs.earthdata.nasa.gov "$HOME/.netrc"; then
        fatal "$HOME/.netrc does not contain CDDIS login information, see usage"
    fi

    local DRY=${DRY:-" >/dev/null"}

    info "Logging into CDDIS..."
    eval $DRY curl\
        -c .urs_cookies \
        -n \
        -k \
        -f -s -S \
        -L \
        $CDDIS_URL/login \

        info "Done"

    info "Copying file to CDDIS..."
    eval $DRY curl -X POST \
        -b .urs_cookies \
        -k \
        -f \
        -F "fileType=VLBI" \
        $(fmtarray ' -F "file[]=@%s"' $@) \
        $CDDIS_URL/upload/
    info "Done"
}


## Commands for Data Centers
CTR_CDDIS="cddis"
CTR_OPAR="pftp ivsopar.obspm.fr"
CTR_BKG="pftp ivs.bkg.bund.de"
CTR_HAYSTACK="pscp evlbi1.haystack.mit.edu:/data-st12/vgos/logs"
CTR_DUMMY="dummy"

# Hack to work around older versions of bash not having asoc arrays
# gets all env variables that start with "CTR_" and assume the rest of
# the name is the key.
CTRS=$(compgen -A variable | grep CTR | cut -c 5- | paste -s -d" ")

# Default Data center
DATA_CENTERS=${DATA_CENTERS:-"CDDIS"}


joinlst () {
    local IFS=" "
    echo "$*" | sed 's/ /, /g' | sed 's/, \(\S*\)$/ or \1/g'
}

# Compress the log to a temp directory
# Do not compress already compressed files
compress() {
    if [[ ${1##*.} == $COMPRESSED_EXT ]]; then
        echo "$1"
        return
    fi

    local ext=${1#*.}
    local name=$(basename "$1")
    local out="/tmp/$name.$COMPRESSED_EXT"

    info Compressing log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "gzip --best -c $1 >  $out"
    else
        $PV "$1" | gzip --best > "$out"
    fi
    echo "$out"
}
# Uncompress the log to a temp directory
uncompress() {
    local name=$(basename $1 .$COMPRESSED_EXT)
    local out="/tmp/$name"

    info Uncompressing log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "gunzip -c $1 >  $out"
    else
        $PV "$1" | gunzip > "$out"
    fi
    echo "$out"
}

# Return a reduced log in /tmp can either be raw or compressed log
reduce() {
    local ext=${1#*.}
    local name=$(basename $(basename "$1" .$ext) $FULL_SUFFIX)
    local out="/tmp/$name.log"
    info Creating reduced log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "zegrep -v "$REDUCE_PATTERN" $1 > $out"
    else
        $PV "$1" | zegrep -v "$REDUCE_PATTERN" > "$out"
    fi
    echo "$out"
}

# Find latest modified log in $LOG_PATH which isn't station or point
get_latest_exp() {
    local log=$(ls -t $LOG_PATH\
        | grep "$STATION\($FULL_SUFFIX\)\?\\.log\(.$COMPRESSED_EXT\)\?\$"\
        | egrep -v '(station|point)'\
        | head -1)

    local ext=${log#*.}
    local expname
    expname=$(basename "$log" .$ext)
    expname=$(basename $expname $FULL_SUFFIX)
    expname=$(basename $expname $STATION)
    echo $expname
}

main () {
    #STATION = Two letter station code, eg "gs"
    CENTERS_OVER=
    LATEST=
    DRY=
    PUSH_PROC=
    COMPRESS=
    QUIET=
    while getopts hltpzc: opt; do
        case $opt in
            l)
                LATEST=1
                ;;
            t)
                DRY=echo
                ;;
            c)
                if [[ ! $CTRS =~ $OPTARG ]]; then
                    fatal "Unknown data center '$OPTARG'"
                fi
                CENTERS_OVER="$CENTERS_OVER $OPTARG"
                ;;
            p)
                PUSH_PROC=1
                ;;
            q)
                QUIET=1
                ;;
            z)
                COMPRESS=1
                ;;
            h)
                usage_long
                exit
                ;;
            *)
                usage >&2
                exit 1
                ;;
            :)
              fatal "Option -$OPTARG requires an argument."
              ;;
        esac
    done
    shift $(($OPTIND - 1))


    set +u
    if [[ -z "$STATION" ]]; then
        fatal "STATION environment variable not set. Set to lower case two-letter station id."
    fi
    set -u

    # Default DATA_CENTERS overridden by flag
    if [[ -n "$CENTERS_OVER" ]]; then
        DATA_CENTERS=$CENTERS_OVER
    fi

    for center in $DATA_CENTERS; do
        set +u
        if [[ -z  "$(eval echo \$CTR_$center)" ]]; then
            fatal "unknown data center center '$center'"
        fi
        set -u
    done

    # If LATEST not set and no arguments, exit
    if [[ -z "$LATEST" && "$#" -eq 0 ]]; then
        usage >&2
        exit 1
    fi

    # List of files or experiment names
    REFS=($@)
    # List of exisiting files that will be pushed
    FILES=()

    if [[ -n "$LATEST" ]]; then
        llog=$(get_latest_exp)
        REFS+=( $llog )
    fi

    for ref in ${REFS[@]}; do
        # First check if the argument looks like a path.
        # If does, check if it is a file.
        # If it's a file, do not process it, just add it to
        # the list; if it isn't, complain and exit.
        if [[ "$ref" =~ /  ]]; then
            if [[-f "$ref" ]]; then
                add $ref
                continue
            else
                fatal "file $ref not found"
            fi
        fi

        # Should we add the proc file?
        if [[ -n "$PUSH_PROC" ]]; then
            proc="$PROC_PATH/$ref$STATION.prc"
            if [[ ! -f "$proc" ]]; then
                fatal "$proc not found"
            fi
            add $proc
        fi

        # If it's not a file, assume it's an observation.
        # Look for a regular log, a full log, or a compressed version of either.
        # If more than one exists, abort and ask the user to deal with it
        log=()
        for f in $LOG_PATH/$ref${STATION}{,$FULL_SUFFIX}.log{,.$COMPRESSED_EXT}; do
            if [[ -f $f ]]; then
                info found $f
                log+=( $f )
            fi
        done
        if [[ ${#log[@]} -lt 1 ]]; then
            fatal "log file for $ref not found"
            exit
        fi
        if [[ ${#log[@]} -gt 1 ]]; then
            fatal "Conflicting log files:"\
                  "\n$(IFS=$'\n';echo -e "${log[*]}")\n"\
                  "Inspect the files and either concatenate them or removed the invalid one(s)."
        fi
        
        # If log contains multicast data, rename to _full.* since we will upload a reduced file
        FULL=
        if zegrep -q "$REDUCE_PATTERN" $log; then
            FULL=1
            logext=${log#*.}
            full=$LOG_PATH/$ref$STATION$FULL_SUFFIX.$logext
            if [[ $log != $full ]]; then
                warn file contains multicast, renaming $(basename $log) to $(basename $full)
                $DRY mv $log $full
            fi
            log=$full
        fi

        # If given '-z' command, compressed file, add it to the queue, and move on
        if [[ -n "$COMPRESS" ]]; then
            add $(compress $log)
            continue
        fi

        # If log doesn't contains data that should be excluded in reduced log, add it to queue and move on.
        if [[ -z "$FULL" ]]; then
            # If log is compressed, extract in a tmp dir upload
            if [[ $log =~ $COMPRESSED_EXT$ ]]; then
                add $(uncompress $log)
                continue
            fi
            add $log
            continue
        fi

        # The log must now contain multicast data, and we haven't been told to upload
        # the full compressed file so generate reduced log and add it to the queue
        add $(reduce $log)
        # To avoid a name conflict, rename the file preserving the extension.
    done

    for center in $DATA_CENTERS; do
        info uploading to $center
        eval \$CTR_$center ${FILES[@]}
    done
}

# Don't run main if file is being "source"d
# Useful for testing
if [[ $0 == "$BASH_SOURCE" ]]; then
    #'strict' mode
    # "-e" exits on error
    # "-u" error on undef variable
    # "-o pipefail" error if any command in a pipe fails
    set -euo pipefail
    main "$@"
fi
